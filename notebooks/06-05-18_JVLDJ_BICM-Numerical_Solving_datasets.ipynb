{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run preample.ipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import specific functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Utilities import *\n",
    "from BiCM import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script solves the BiCM for some of the datasets we are analyzing\n",
    "\n",
    "## Numerical Solving BiCM\n",
    "    - Get degree sequences\n",
    "    - run numerical simulation to solve system\n",
    "    - calculate the link probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_degree_sequences(M_hat):\n",
    "    \n",
    "    degree_sequence_item = np.sum(M_hat,1)\n",
    "    degree_sequence_product = np.sum(M_hat,0)\n",
    "    degree_sequence = list(np.concatenate([degree_sequence_item, degree_sequence_product]))\n",
    "    n_rows = len(degree_sequence_item)\n",
    "    n_cols = len(degree_sequence_product)\n",
    "    return degree_sequence, n_rows, n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_link_probabilities(M, solver = 'root'):\n",
    "    [degree_sequence, n_rows, n_cols] = get_degree_sequences(M)\n",
    "    bicm = bicm_leastSquares(degree_sequence, n_rows, n_cols)\n",
    "    if solver == 'root':\n",
    "        bicm.solve_root()\n",
    "    if solver == 'least_squares':\n",
    "        bicm.solve_least_squares()\n",
    "    if solver == 'trust_region':\n",
    "        bicm.solve_trust_regions()\n",
    "    bicm.generate_p_adjacency()\n",
    "    return bicm.p_adjacency, abs(np.sum(bicm.final_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movielens_adjacency_unweighted_iter_9.csv\n",
      "solved 1437.7869088281318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:22<03:19, 22.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 678, initial cost 4.5057e+06, final cost 5.4438e+03, first-order optimality 5.71e+03.\n",
      "solvedls 123.90854761411191\n",
      "unsolved movielens_adjacency_unweighted_iter_9.csv\n",
      "movielens_adjacency_unweighted_iter_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:25<02:12, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solved 1.871021178888273e-11\n",
      "movielens_adjacency_unweighted_iter_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:29<01:28, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solved 4.574304384712592e-11\n",
      "movielens_adjacency_unweighted_iter_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:32<00:59,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solved 6.00321906055689e-11\n",
      "movielens_adjacency_unweighted_iter_3.csv\n",
      "solved 972.208153108333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:53<01:06, 13.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 688, initial cost 4.3682e+06, final cost 5.4125e+03, first-order optimality 6.25e+03.\n",
      "solvedls 50.00618296888743\n",
      "unsolved movielens_adjacency_unweighted_iter_3.csv\n",
      "movielens_adjacency_unweighted_iter_6.csv\n",
      "solved 4651.750716235345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [01:17<01:05, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 727, initial cost 4.3965e+06, final cost 3.8801e+03, first-order optimality 7.73e+03.\n",
      "solvedls 121.96318732228764\n",
      "unsolved movielens_adjacency_unweighted_iter_6.csv\n",
      "movielens_adjacency_unweighted_iter_8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [01:20<00:37, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solved 6.321943390678721e-11\n",
      "movielens_adjacency_unweighted_iter_7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [01:23<00:19,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solved 3.9546145392743915e-13\n",
      "movielens_adjacency_unweighted_iter_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [01:27<00:07,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solved 2.636995320509916e-11\n",
      "movielens_adjacency_unweighted_iter_5.csv\n",
      "solved 448.7330841840209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [01:52<00:00, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 817, initial cost 4.6683e+06, final cost 5.7506e+03, first-order optimality 2.79e+03.\n",
      "solvedls 18.071669689541153\n",
      "unsolved movielens_adjacency_unweighted_iter_5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_dir = '../data/intermediate/movielens/adjacency_link_removed/'\n",
    "\n",
    "for file in tqdm(os.listdir(file_dir)):\n",
    "    print(file)\n",
    "    adj = np.loadtxt(file_dir + file, delimiter=',').astype(int)\n",
    "    \n",
    "    original_path = '../data/intermediate/movielens/adjacency/movielens_adjacency_unweighted.csv'\n",
    "    original_matrix = np.loadtxt(original_path, delimiter=',').astype(int)\n",
    "    num_removed_links = np.sum(original_matrix) - np.sum(adj)\n",
    "    \n",
    "    p_adj, cost = get_link_probabilities(adj)\n",
    "    print('solved', cost)\n",
    "    if cost > 1:\n",
    "        p_adj, cost = get_link_probabilities(adj, 'least_squares')\n",
    "        print('solvedls', cost)\n",
    "    if cost > 1:\n",
    "        print('unsolved', file)\n",
    "        continue\n",
    "    np.savetxt('../data/intermediate/movielens/probabilities_adjacency/' + file, p_adj)\n",
    "    assert cost < 1, 'numerical convergence problems'\n",
    "    df = sort_probabilities(p_adj, adj)\n",
    "    R = fill_miss_links(df, adj, num_removed_links, 0)\n",
    "    np.savetxt('../data/intermediate/movielens/adjacency_reconstructed/' + file, R)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Trade Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_links(A, frac = 0.1):\n",
    "    nonzero = zip(*np.nonzero(A))\n",
    "    len_nonzeros = len(list(nonzero))\n",
    "    nonzero = list(zip(*np.nonzero(A)))\n",
    "    N_links_remove = int(len_nonzeros*frac)\n",
    "    idx_to_remove = np.random.choice(len_nonzeros, N_links_remove, replace=False)\n",
    "\n",
    "    A_hat = A.copy()\n",
    "    for idx in idx_to_remove:\n",
    "        A_hat[nonzero[idx]] = 0\n",
    "    removed_links = [nonzero[i] for i in idx_to_remove]\n",
    "    return A_hat, removed_links\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj = np.genfromtxt('../data/raw/Mcp_2000.dat')\n",
    "adj = adj.astype(int)\n",
    "np.savetxt('../data/intermediate/wtw/adjacency/wtw_2000.csv', adj)\n",
    "\n",
    "file_dir = '../data/intermediate/wtw/adjacency_link_removed/'\n",
    "for i in np.arange(15):\n",
    "    adj_removed = remove_links(adj)[0]\n",
    "    print(np.sum(adj))\n",
    "    print(np.sum(adj_removed))\n",
    "    np.savetxt(file_dir + 'wtw_2000_' + str(i) + '.csv', adj_removed, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "file_dir = '../data/intermediate/wtw/adjacency_link_removed/'\n",
    "\n",
    "for file in tqdm(os.listdir(file_dir)):\n",
    "    print(file)\n",
    "    adj = np.loadtxt(file_dir + file).astype(int)\n",
    "    \n",
    "    original_path = '../data/intermediate/wtw/adjacency/wtw_2000.csv'\n",
    "    original_matrix = np.loadtxt(original_path)\n",
    "    num_removed_links = np.sum(original_matrix) - np.sum(adj)\n",
    "    \n",
    "    p_adj, cost = get_link_probabilities(adj)\n",
    "    print('solved', cost)\n",
    "    if cost > 1:\n",
    "        p_adj, cost = get_link_probabilities(adj, 'least_squares')\n",
    "        print('solvedls', cost)\n",
    "    if cost > 1:\n",
    "        print('unsolved', file)\n",
    "        continue\n",
    "    np.savetxt('../data/intermediate/wtw/probabilities_adjacency/p_' + file, p_adj)\n",
    "    assert cost < 1, 'numerical convergence problems'\n",
    "    df = sort_probabilities(p_adj, adj)\n",
    "    R = fill_miss_links(df, adj, num_removed_links, 0)\n",
    "    np.savetxt('../data/intermediate/wtw/adjacency_reconstructed/r_' + file, R)\n",
    "    #np.savetxt('../data/intermediate/wtw/probabilities_adjacency/p_' + file, p_adj)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adj = np.loadtxt('../data/intermediate/toy_models/adjacency/straight_bip.csv', adj)\n",
    "import os\n",
    "\n",
    "file_dir = '../data/intermediate/toy_models/adjacency/'\n",
    "file_dir_rem = '../data/intermediate/toy_models/adjacency_link_removed/'\n",
    "for file in tqdm(os.listdir(file_dir)):\n",
    "    print(file)\n",
    "    print(file_dir + file)\n",
    "    adj = np.loadtxt(file_dir + file, delimiter=',').astype(int)\n",
    "    for i in np.arange(15):\n",
    "        adj_removed = remove_links(adj)[0]\n",
    "        print(np.sum(adj))\n",
    "        print(np.sum(adj_removed))\n",
    "        np.savetxt(file_dir_rem + file[:-4] + '_' +  str(i) + '.csv', adj_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "file_dir = '../data/intermediate/toy_models/adjacency_link_removed/'\n",
    "\n",
    "for file in tqdm(os.listdir(file_dir)):\n",
    "    print(file)\n",
    "    adj = np.loadtxt(file_dir + file).astype(int)\n",
    "    \n",
    "    if file[0] == 'b':\n",
    "        original_path = '../data/intermediate/toy_models/adjacency/blocks_bip.csv' \n",
    "        original_matrix = np.loadtxt(original_path, delimiter=',').astype(int)\n",
    "    if file[0] == 's':\n",
    "        original_path = '../data/intermediate/toy_models/adjacency/straight_bip.csv' \n",
    "        original_matrix = np.loadtxt(original_path, delimiter=',').astype(int)\n",
    "    if file[0] == 'h':\n",
    "        original_path = '../data/intermediate/toy_models/adjacency/hight_dense_bip.csv' \n",
    "        original_matrix = np.loadtxt(original_path, delimiter=',').astype(int)\n",
    "    if file[0] == 'l':\n",
    "        original_path = '../data/intermediate/toy_models/adjacency/low_dense_bip.csv' \n",
    "        original_matrix = np.loadtxt(original_path, delimiter=',').astype(int)\n",
    "        \n",
    "        \n",
    "    num_removed_links = np.sum(original_matrix) - np.sum(adj)\n",
    "    \n",
    "    p_adj, cost = get_link_probabilities(adj)\n",
    "    print('solved', cost)\n",
    "    if cost > 1:\n",
    "        p_adj, cost = get_link_probabilities(adj, 'least_squares')\n",
    "        print('solvedls', cost)\n",
    "    if cost > 1:\n",
    "        print('unsolved', file)\n",
    "        continue\n",
    "    np.savetxt('../data/intermediate/toy_models/probabilities_adjacency/' + file, p_adj)\n",
    "    assert cost < 1, 'numerical convergence problems'\n",
    "    df = sort_probabilities(p_adj, adj)\n",
    "    R = fill_miss_links(df, adj, num_removed_links, 0)\n",
    "    np.savetxt('../data/intermediate/toy_models/adjacency_reconstructed/' + file, R)\n",
    "    np.savetxt('../data/intermediate/toy_models/probabilities_adjacency/' + file, p_adj)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Venezuelan Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "file_dir = '../data/intermediate/bank/adjacency_link_removed/'\n",
    "\n",
    "for file in tqdm(os.listdir(file_dir)):\n",
    "    adj = np.loadtxt(file_dir + file, delimiter=',').astype(int)\n",
    "    \n",
    "    original_path = '../data/intermediate/bank/adjacency/' + file[0:9] + file[14:20] + '.csv'\n",
    "    original_matrix = np.loadtxt(original_path, delimiter=',').astype(int)\n",
    "    num_removed_links = np.sum(original_matrix) - np.sum(adj)\n",
    "    \n",
    "    p_adj, cost = get_link_probabilities(adj)\n",
    "    if cost > 1:\n",
    "        p_adj, cost = get_link_probabilities(adj, 'least_squares')\n",
    "    if cost > 1:\n",
    "        continue\n",
    "    #assert cost < 1, 'numerical convergence problems'\n",
    "    df = sort_probabilities(p_adj, adj)\n",
    "    R = fill_miss_links(df, adj, num_removed_links, 0)\n",
    "    np.savetxt('../data/intermediate/bank/adjacency_reconstructed/' + file, R)\n",
    "    np.savetxt('../data/intermediate/bank/probabilities_adjacency/' + file, p_adj)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "#sparse_matrix = scipy.sparse.load_npz('../data/raw/amazon_adjacency_unweighted/amazon_video_games.npz')\n",
    "sparse_matrix = scipy.sparse.load_npz('../data/raw/amazon_music_adjacency_unweighted/amazon_music_instruments.npz')\n",
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_hat = sparse_matrix.copy()\n",
    "degree_sequence_item = np.sum(M_hat,1)\n",
    "degree_sequence_product = np.transpose(np.sum(M_hat,0))\n",
    "degree_sequence = list(np.concatenate([degree_sequence_item, degree_sequence_product]))\n",
    "n_rows = len(degree_sequence_item)\n",
    "n_cols = len(degree_sequence_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bicm = bicm_leastSquares(degree_sequence, n_rows, n_cols)\n",
    "bicm.final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second try using the first iteration results as initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0_2 = np.concatenate([np.unique(bicm.x), np.unique(bicm.y)])\n",
    "bicm.solve_least_squares(initial_guess=x0_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
